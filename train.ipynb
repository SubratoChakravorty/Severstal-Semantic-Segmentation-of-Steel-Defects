{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project D - Severstal Steel Defect Detection Kaggle Competition \n",
    "## Semantic Segmentation of steel defects\n",
    "### Authors: Utkrisht Rajkumar, Subrato Chakravorty, Chi-Hsin Lo\n",
    "\n",
    "This is the file used to train and benchmark each of the different models we trained and tested using Keras. The models we tested are \n",
    "1. Original U-Net with less filters per layer --> **UNet**\n",
    "2. U-Net with ResNet like encoder + multi-scale context aggregation with dilated convolutions (MCAD) --> **UNet_Res**\n",
    "3. Modified DeepLabv3+ with mobilenet backbone with less parameters --> **deeplabv3**\n",
    "4. U-Net with inverted ResNet encoder (borrowed from deeplab) + MCAD --> **UNet_InvRes**\n",
    "\n",
    "Note: To use DeepLabv3+, change instances of keras to tf.keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import gc\n",
    "import cv2\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras import layers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import concatenate, Input\n",
    "from keras.layers import *\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import Callback, ModelCheckpoint\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import multi_gpu_model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '../input/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create folders for: (1) training loss/accuracy history, (2) trained model, (3) submission.csv for Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(os.path.exists(('./submissions'))):\n",
    "      pass\n",
    "else:\n",
    "    os.mkdir('./submissions')\n",
    "\n",
    "if(os.path.exists(('./historys'))):\n",
    "    pass\n",
    "else:\n",
    "    os.mkdir('./history')\n",
    "\n",
    "if(os.path.exists(('./models'))):\n",
    "      pass\n",
    "else:\n",
    "    os.mkdir('./models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define loss and accuracy metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "from keras.metrics import binary_crossentropy\n",
    "def dice_coef(y_true, y_pred, smooth=1):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_loss(y_true,y_pred):\n",
    "    return 1-dice_coef(y_true,y_pred)\n",
    "\n",
    "def BCE_loss(y_true, y_pred):\n",
    "    return (binary_crossentropy(y_true, y_pred))\n",
    "\n",
    "def bce_dice(y_true, y_pred):\n",
    "    return BCE_loss(y_true, y_pred) + dice_loss(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load all models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from model import UNet, Deeplabv3\n",
    "unet = UNet((256, 1600, 1))\n",
    "unet_res = UNet((256, 1600, 1), MCAD=True, res_encoder=True)\n",
    "unet_invres = UNet((256, 1600, 1), inv_res = True, MCAD=True)\n",
    "#deeplabv3 = Deeplabv3(input_shape=(256, 1600, 1), alpha =0.3, classes=4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unet.compile(optimizer='adam', loss=bce_dice, metrics=[dice_coef])\n",
    "unet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_res.compile(optimizer='adam', loss=bce_dice, metrics=[dice_coef])\n",
    "unet_res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabv3.compile(optimizer='adam', loss=bce_dice, metrics=[dice_coef])\n",
    "deeplabv3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_invres.compile(optimizer='adam', loss=bce_dice, metrics=[dice_coef])\n",
    "unet_invres.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data \n",
    "\n",
    "Remove all images with no defects at all. Only keep images with at least 1 defect. There are 4 defects total. An image can have multiple types of defects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "train_path = root_dir + 'train.csv'\n",
    "train_df = pd.read_csv(train_path)\n",
    "train_df['ImageId'] = train_df['ImageId_ClassId'].apply(lambda x: x.split('_')[0])\n",
    "train_df['ClassId'] = train_df['ImageId_ClassId'].apply(lambda x: x.split('_')[1])\n",
    "train_df['hasMask'] = ~ train_df['EncodedPixels'].isna()\n",
    "mask_count_df = train_df.groupby('ImageId').agg(np.sum).reset_index()\n",
    "mask_count_df.sort_values('hasMask', ascending=False, inplace=True)\n",
    "non_missing_train_idx = mask_count_df[mask_count_df['hasMask'] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": false
   },
   "outputs": [],
   "source": [
    "def post_process(probability, threshold=0.5, min_size=3000):\n",
    "    '''Post processing of each predicted mask, components with lesser number of pixels\n",
    "    than `min_size` are ignored'''\n",
    "    mask = probability >= 0.5\n",
    "    num_component, component = cv2.connectedComponents(mask.astype(np.uint8))\n",
    "    predictions = np.zeros((256, 1600), np.float32)\n",
    "    for c in range(1, num_component):\n",
    "        p = (component == c)\n",
    "        if p.sum() > min_size:\n",
    "            predictions[p] = 1\n",
    "    return predictions\n",
    "\n",
    "def mask2rle(img):\n",
    "    pixels= img.T.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "def rle2mask(rle, input_shape):\n",
    "    width, height = input_shape[:2]\n",
    "    mask= np.zeros( width*height ).astype(np.uint8)\n",
    "    array = np.asarray([int(x) for x in rle.split()])\n",
    "    starts = array[0::2]\n",
    "    lengths = array[1::2]\n",
    "    current_position = 0\n",
    "    for index, start in enumerate(starts):\n",
    "        mask[int(start):int(start+lengths[index])] = 1\n",
    "        current_position += lengths[index]\n",
    "    return mask.reshape(height, width).T\n",
    "\n",
    "def build_masks(rles, input_shape):\n",
    "    depth = len(rles)\n",
    "    masks = np.zeros((*input_shape, depth))\n",
    "    for i, rle in enumerate(rles):\n",
    "        if type(rle) is str:\n",
    "            masks[:, :, i] = rle2mask(rle, input_shape)\n",
    "    return masks\n",
    "\n",
    "def build_rles(masks):\n",
    "    width, height, depth = masks.shape\n",
    "    rles = [mask2rle(post_process(masks[:, :, i])) for i in range(depth)]\n",
    "    return rles\n",
    "\n",
    "def post_process(probability, threshold=0.5, min_size=3000):\n",
    "    '''Post processing of each predicted mask, components with lesser number of pixels\n",
    "    than `min_size` are ignored'''\n",
    "    mask = probability >= 0.5\n",
    "    num_component, component = cv2.connectedComponents(mask.astype(np.uint8))\n",
    "    predictions = np.zeros((256, 1600), np.float32)\n",
    "    for c in range(1, num_component):\n",
    "        p = (component == c)\n",
    "        if p.sum() > min_size:\n",
    "            predictions[p] = 1\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    #'Generates data for Keras'\n",
    "    def __init__(self, list_IDs, df, target_df=None, mode='fit', base_path='../input/train_images', batch_size=32, \n",
    "                 dim=(256, 1600), n_channels=1, n_classes=4, random_state=2019, shuffle=True):\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.df = df\n",
    "        self.mode = mode\n",
    "        self.base_path = base_path\n",
    "        self.target_df = target_df\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.random_state = random_state     \n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        #'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        #'Generate one batch of data'\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        # Find list of IDs\n",
    "        list_IDs_batch = [self.list_IDs[k] for k in indexes]\n",
    "        X = self.__generate_X(list_IDs_batch)\n",
    "        if self.mode == 'fit':\n",
    "            y = self.__generate_y(list_IDs_batch)\n",
    "            return X, y\n",
    "        elif self.mode == 'predict':\n",
    "            return X\n",
    "        else:\n",
    "            raise AttributeError('The mode parameter should be set to \"fit\" or \"predict\".')\n",
    "        \n",
    "    def on_epoch_end(self):\n",
    "        #'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.seed(self.random_state)\n",
    "            np.random.shuffle(self.indexes)\n",
    "    \n",
    "    def __generate_X(self, list_IDs_batch):\n",
    "        #'Generates data containing batch_size samples'\n",
    "        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
    "        for i, ID in enumerate(list_IDs_batch):\n",
    "            im_name = self.df['ImageId'].iloc[ID]\n",
    "            img_path = f\"{self.base_path}/{im_name}\"\n",
    "            img = self.__load_grayscale(img_path)\n",
    "            X[i,] = img\n",
    "        return X\n",
    "    \n",
    "    def __generate_y(self, list_IDs_batch):\n",
    "        y = np.empty((self.batch_size, *self.dim, self.n_classes), dtype=int)\n",
    "        for i, ID in enumerate(list_IDs_batch):\n",
    "            im_name = self.df['ImageId'].iloc[ID]\n",
    "            image_df = self.target_df[self.target_df['ImageId'] == im_name]\n",
    "            rles = image_df['EncodedPixels'].values\n",
    "            masks = build_masks(rles, input_shape=self.dim)\n",
    "            y[i, ] = masks\n",
    "        return y\n",
    "    \n",
    "    def __load_grayscale(self, img_path):\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        img = img.astype(np.float32) / 255.\n",
    "        img = np.expand_dims(img, axis=-1)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create training and validation dataing. 95-5 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "\n",
    "train = np.array(non_missing_train_idx.index)\n",
    "\n",
    "np.random.shuffle(train)\n",
    "train_num = int(len(train)*0.95)\n",
    "train_idx = train[:train_num]\n",
    "val_idx = train[train_num:]\n",
    "\n",
    "train_gen = DataGenerator(train_idx, df=mask_count_df, target_df=train_df, batch_size=BATCH_SIZE, n_classes=4)\n",
    "val_gen = DataGenerator(val_idx, df=mask_count_df, target_df=train_df, batch_size=BATCH_SIZE, n_classes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_name = 'unet'\n",
    "model_path = './models/' + model_name + '.h5'\n",
    "chkpt = ModelCheckpoint(model_path, monitor='val_dice_coef', save_best_only=True, save_weights_only=False,mode='auto')\n",
    "history = UNet.fit_generator(train_gen, validation_data=val_gen, callbacks=[chkpt], use_multiprocessing=False, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "history_df = pd.DataFrame(history.history)\n",
    "history_df[['loss', 'val_loss']].plot()\n",
    "history_df[['dice_coef', 'val_dice_coef']].plot()\n",
    "history_path = './history/' + model_name + '_history.csv'\n",
    "history_df.to_csv(history_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "model = load_model(model_name, custom_objects={'dice_coef': dice_coef})\n",
    "sample_path = root_dir + 'sample_submission.csv'\n",
    "sub_df = pd.read_csv(sample_path)\n",
    "sub_df['ImageId'] = sub_df['ImageId_ClassId'].apply(lambda x: x.split('_')[0])\n",
    "test_imgs = pd.DataFrame(sub_df['ImageId'].unique(), columns=['ImageId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = []\n",
    "for i in range(0, test_imgs.shape[0], 300):\n",
    "    batch_idx = list(range(i, min(test_imgs.shape[0], i + 300)))\n",
    "    test_generator = DataGenerator(batch_idx, df=test_imgs, shuffle=False,mode='predict',base_path='../input/test_images',\n",
    "        target_df=sub_df, batch_size=1, n_classes=4)\n",
    "    batch_pred_masks = model.predict_generator(test_generator, workers=1, verbose=1, use_multiprocessing=False)\n",
    "    \n",
    "    for j, b in tqdm(enumerate(batch_idx)):\n",
    "        filename = test_imgs['ImageId'].iloc[b]\n",
    "        image_df = sub_df[sub_df['ImageId'] == filename].copy()\n",
    "        \n",
    "        pred_masks = batch_pred_masks[j, ].round().astype(int)\n",
    "        pred_rles = build_rles(pred_masks)\n",
    "        \n",
    "        image_df['EncodedPixels'] = pred_rles\n",
    "        test_df.append(image_df)\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate submission file for Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[['ImageId_ClassId', 'EncodedPixels']].to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
