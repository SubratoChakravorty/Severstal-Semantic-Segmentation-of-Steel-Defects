{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nightshade/anaconda3/envs/testenv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/nightshade/anaconda3/envs/testenv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/nightshade/anaconda3/envs/testenv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/nightshade/anaconda3/envs/testenv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/nightshade/anaconda3/envs/testenv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/nightshade/anaconda3/envs/testenv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/nightshade/anaconda3/envs/testenv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/nightshade/anaconda3/envs/testenv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/nightshade/anaconda3/envs/testenv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/nightshade/anaconda3/envs/testenv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/nightshade/anaconda3/envs/testenv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/nightshade/anaconda3/envs/testenv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import gc\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras import layers\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.python.keras.models import Model, load_model\n",
    "from tensorflow.python.keras.layers import concatenate, Input\n",
    "from tensorflow.python.keras.layers import *\n",
    "from tensorflow.python.keras.optimizers import Adam\n",
    "from tensorflow.python.keras.callbacks import Callback, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.keras.utils import multi_gpu_model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../input/train.csv')\n",
    "train_df = train_df.head(1000)\n",
    "train_df['ImageId'] = train_df['ImageId_ClassId'].apply(lambda x: x.split('_')[0])\n",
    "train_df['ClassId'] = train_df['ImageId_ClassId'].apply(lambda x: x.split('_')[1])\n",
    "train_df['hasMask'] = ~ train_df['EncodedPixels'].isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_count_df = train_df.groupby('ImageId').agg(np.sum).reset_index()\n",
    "mask_count_df.sort_values('hasMask', ascending=False, inplace=True)\n",
    "non_missing_train_idx = mask_count_df[mask_count_df['hasMask'] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": false
   },
   "outputs": [],
   "source": [
    "def mask2rle(img):\n",
    "    pixels= img.T.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "def rle2mask(rle, input_shape):\n",
    "    width, height = input_shape[:2]\n",
    "    \n",
    "    mask= np.zeros( width*height ).astype(np.uint8)\n",
    "    \n",
    "    array = np.asarray([int(x) for x in rle.split()])\n",
    "    starts = array[0::2]\n",
    "    lengths = array[1::2]\n",
    "\n",
    "    current_position = 0\n",
    "    for index, start in enumerate(starts):\n",
    "        mask[int(start):int(start+lengths[index])] = 1\n",
    "        current_position += lengths[index]\n",
    "        \n",
    "    return mask.reshape(height, width).T\n",
    "\n",
    "def build_masks(rles, input_shape):\n",
    "    depth = len(rles)\n",
    "    masks = np.zeros((*input_shape, depth))\n",
    "    \n",
    "    for i, rle in enumerate(rles):\n",
    "        if type(rle) is str:\n",
    "            masks[:, :, i] = rle2mask(rle, input_shape)\n",
    "    \n",
    "    return masks\n",
    "\n",
    "def build_rles(masks):\n",
    "    width, height, depth = masks.shape\n",
    "    \n",
    "    rles = [mask2rle(masks[:, :, i])\n",
    "            for i in range(depth)]\n",
    "    \n",
    "    return rles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs, df, target_df=None, mode='fit',\n",
    "                 base_path='../input/train_images',\n",
    "                 batch_size=32, dim=(256, 1600), n_channels=1,\n",
    "                 n_classes=4, random_state=2019, shuffle=True):\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.df = df\n",
    "        self.mode = mode\n",
    "        self.base_path = base_path\n",
    "        self.target_df = target_df\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.random_state = random_state\n",
    "        \n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_batch = [self.list_IDs[k] for k in indexes]\n",
    "        \n",
    "        X = self.__generate_X(list_IDs_batch)\n",
    "        \n",
    "        if self.mode == 'fit':\n",
    "            y = self.__generate_y(list_IDs_batch)\n",
    "            return X, y\n",
    "        \n",
    "        elif self.mode == 'predict':\n",
    "            return X\n",
    "\n",
    "        else:\n",
    "            raise AttributeError('The mode parameter should be set to \"fit\" or \"predict\".')\n",
    "        \n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.seed(self.random_state)\n",
    "            np.random.shuffle(self.indexes)\n",
    "    \n",
    "    def __generate_X(self, list_IDs_batch):\n",
    "        'Generates data containing batch_size samples'\n",
    "        # Initialization\n",
    "        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
    "        \n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_batch):\n",
    "            im_name = self.df['ImageId'].iloc[ID]\n",
    "            img_path = f\"{self.base_path}/{im_name}\"\n",
    "            img = self.__load_grayscale(img_path)\n",
    "            \n",
    "            # Store samples\n",
    "            X[i,] = img\n",
    "\n",
    "        return X\n",
    "    \n",
    "    def __generate_y(self, list_IDs_batch):\n",
    "        y = np.empty((self.batch_size, *self.dim, self.n_classes), dtype=int)\n",
    "        \n",
    "        for i, ID in enumerate(list_IDs_batch):\n",
    "            im_name = self.df['ImageId'].iloc[ID]\n",
    "            image_df = self.target_df[self.target_df['ImageId'] == im_name]\n",
    "            \n",
    "            rles = image_df['EncodedPixels'].values\n",
    "            masks = build_masks(rles, input_shape=self.dim)\n",
    "            \n",
    "            y[i, ] = masks\n",
    "\n",
    "        return y\n",
    "    \n",
    "    def __load_grayscale(self, img_path):\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        img = img.astype(np.float32) / 255.\n",
    "        img = np.expand_dims(img, axis=-1)\n",
    "\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "\n",
    "train = np.array(non_missing_train_idx.index)\n",
    "\n",
    "np.random.shuffle(train)\n",
    "train_num = int(len(train)*0.95)\n",
    "train_idx = train[:train_num]\n",
    "val_idx = train[train_num:]\n",
    "\n",
    "train_generator = DataGenerator(\n",
    "    train_idx, \n",
    "    df=mask_count_df,\n",
    "    target_df=train_df,\n",
    "    batch_size=BATCH_SIZE, \n",
    "    n_classes=4\n",
    ")\n",
    "\n",
    "val_generator = DataGenerator(\n",
    "    val_idx, \n",
    "    df=mask_count_df,\n",
    "    target_df=train_df,\n",
    "    batch_size=BATCH_SIZE, \n",
    "    n_classes=4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred, smooth=1):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape):\n",
    "    num_classes = 4\n",
    "    width = 8\n",
    "    def conv_block(x, width, k_reg=False):\n",
    "        c1 = Conv2D(width, (3, 3), activation='relu', padding='same') (x)\n",
    "        c1 = Conv2D(width, (3, 3), activation='relu', padding='same') (c1)\n",
    "        return c1\n",
    "\n",
    "    inputs = Input(input_shape)\n",
    "    activation = 'sigmoid'\n",
    "    c1 = conv_block(inputs, width)\n",
    "    p1 = MaxPooling2D((2, 2)) (c1)\n",
    "\n",
    "    c2 = conv_block(p1, width*2, k_reg=True)\n",
    "    p2 = MaxPooling2D((2, 2)) (c2)\n",
    "\n",
    "    c3 = conv_block(p2, width*4, k_reg=True)\n",
    "    p3 = MaxPooling2D((2, 2)) (c3)\n",
    "\n",
    "    c4 = conv_block(p3, width*8, k_reg=True)\n",
    "    p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
    "\n",
    "    c5 = conv_block(p4, width*16)\n",
    "    p5 = MaxPooling2D(pool_size=(2, 2)) (c5)\n",
    "    \n",
    "    cm = conv_block(p5, width*8)\n",
    "    m1 = Conv2D(width*8, (3, 3), activation='relu', dilation_rate = 2, padding='same') (cm)\n",
    "    m2 = Conv2D(width*8, (3, 3), activation='relu', dilation_rate = 4, padding='same') (m1)\n",
    "    m3 = Conv2D(width*8, (3, 3), activation='relu', dilation_rate = 8, padding='same') (m2)\n",
    "    m4 = Conv2D(width*8, (3, 3), activation='relu', dilation_rate = 16, padding='same') (m2)\n",
    "    cm = concatenate([cm, m1, m2, m3, m4])\n",
    "    \n",
    "    um = Conv2DTranspose(width*16, (2, 2), strides=(2, 2), padding='same') (cm)\n",
    "    um = concatenate([um, c5])\n",
    "    cm = conv_block(um, width*16)\n",
    "\n",
    "    u6 = Conv2DTranspose(width*8, (2, 2), strides=(2, 2), padding='same') (cm)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    c6 = conv_block(u6, width*8)\n",
    "\n",
    "    u7 = Conv2DTranspose(width*4, (2, 2), strides=(2, 2), padding='same') (c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    c7 = conv_block(u7, width*4)\n",
    "\n",
    "    u8 = Conv2DTranspose(width*2, (2, 2), strides=(2, 2), padding='same') (c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    c8 = conv_block(u8, width*2)\n",
    "\n",
    "    u9 = Conv2DTranspose(width, (2, 2), strides=(2, 2), padding='same') (c8)\n",
    "    u9 = concatenate([u9, c1], axis=3)\n",
    "    c9 = conv_block(u9, width)\n",
    "\n",
    "    outputs = Conv2D(num_classes, (1, 1), activation=activation) (c9)\n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[dice_coef])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_kg_hide-output": true,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-5cc6946e2a96>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# model = build_model((256, 1600, 1))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDeeplabv3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDeeplabv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1600\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'model'"
     ]
    }
   ],
   "source": [
    "# model = build_model((256, 1600, 1))\n",
    "from model import Deeplabv3\n",
    "model = Deeplabv3(input_shape=(256, 1600, 1), classes=4)  \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#/model = multi_gpu_model(model, gpus=4)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[dice_coef])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\n",
    "    'base_UNET_MCAD.h5', \n",
    "    monitor='val_dice_coef', \n",
    "    verbose=0, \n",
    "    save_best_only=True, \n",
    "    save_weights_only=False,\n",
    "    mode='auto'\n",
    ")\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=[checkpoint],\n",
    "    use_multiprocessing=False,\n",
    "    workers=1,\n",
    "    epochs=20\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# if the model learns, then add function for context module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "history_df = pd.DataFrame(history.history)\n",
    "history_df[['loss', 'val_loss']].plot()\n",
    "history_df[['dice_coef', 'val_dice_coef']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df.to_csv('history/base_UNET_MCAD_history.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = val_generator.__getitem__(6)\n",
    "print(len(test), test[0].shape, test[1].shape)\n",
    "plt.imshow(np.squeeze(test[0][0])); plt.show()\n",
    "plt.imshow(test[1][0][...,0]); plt.show()\n",
    "plt.imshow(test[1][0][...,1]); plt.show()\n",
    "plt.imshow(test[1][0][...,2]); plt.show()\n",
    "plt.imshow(test[1][0][...,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = np.squeeze(model.predict(np.expand_dims(test[0][0], axis=0)))\n",
    "plt.imshow(np.squeeze(test_pred)[...,0]); plt.show()\n",
    "plt.imshow(np.squeeze(test_pred)[...,1]); plt.show()\n",
    "plt.imshow(np.squeeze(test_pred)[...,2]); plt.show()\n",
    "plt.imshow(np.squeeze(test_pred)[...,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img(code, base, resize=True):\n",
    "    path = f'{base}/{code}'\n",
    "    img = cv2.imread(path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    if resize:\n",
    "        img = cv2.resize(img, (256, 256))\n",
    "    \n",
    "    return img\n",
    "\n",
    "def validate_path(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "model = load_model('base_UNET_MCAD.h5', custom_objects={'dice_coef': dice_coef})\n",
    "sub_df = pd.read_csv('../input/sample_submission.csv')\n",
    "sub_df['ImageId'] = sub_df['ImageId_ClassId'].apply(lambda x: x.split('_')[0])\n",
    "test_imgs = pd.DataFrame(sub_df['ImageId'].unique(), columns=['ImageId'])\n",
    "test_imgs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = DataGenerator(test_imgs.index, df=test_imgs, shuffle=False, mode='predict', target_df=test_imgs,\n",
    "        base_path='../input/test_images',\n",
    "        batch_size=BATCH_SIZE,\n",
    "        n_classes=4\n",
    "    )\n",
    "test_df = []\n",
    "\n",
    "for i in range(0, test_imgs.shape[0], 300):\n",
    "    batch_idx = list(\n",
    "        range(i, min(test_imgs.shape[0], i + 300))\n",
    "    )\n",
    "    \n",
    "    test_generator = DataGenerator(batch_idx, df=test_imgs, shuffle=False,mode='predict',base_path='../input/test_images',\n",
    "        target_df=sub_df,\n",
    "        batch_size=1,\n",
    "        n_classes=4\n",
    "    )\n",
    "    \n",
    "    batch_pred_masks = model.predict_generator(\n",
    "        test_generator, \n",
    "        workers=1,\n",
    "        verbose=1,\n",
    "        use_multiprocessing=False\n",
    "    )\n",
    "    \n",
    "    for j, b in tqdm(enumerate(batch_idx)):\n",
    "        filename = test_imgs['ImageId'].iloc[b]\n",
    "        image_df = sub_df[sub_df['ImageId'] == filename].copy()\n",
    "        \n",
    "        pred_masks = batch_pred_masks[j, ].round().astype(int)\n",
    "        pred_rles = build_rles(pred_masks)\n",
    "        \n",
    "        image_df['EncodedPixels'] = pred_rles\n",
    "        test_df.append(image_df)\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.concat(test_df)\n",
    "print(test_df.shape)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[['ImageId_ClassId', 'EncodedPixels']].to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
